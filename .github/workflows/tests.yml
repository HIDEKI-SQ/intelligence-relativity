name: Tests

on:
  push:
    branches:
      - main
      - develop
  pull_request:
    branches:
      - main
  workflow_dispatch:

jobs:
  test:
    name: Run Test Suite
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    strategy:
      matrix:
        python-version:
          - '3.11'
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
        cache: 'pip'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-html
    
    - name: Install package in development mode
      run: |
        pip install -e .
    
    - name: Install optional dependencies
      continue-on-error: true
      run: |
        pip install transformers torch
    
    - name: Verify environment
      run: |
        echo "Python version:"
        python --version
        echo ""
        echo "Installed packages:"
        pip list
        echo ""
        echo "Python path:"
        python -c "import sys; print('\n'.join(sys.path))"
        echo ""
        echo "NumPy configuration:"
        python -c "import numpy; numpy.show_config()"
    
    - name: Verify src module is importable
      run: |
        python -c "from src.core import set_deterministic_mode; print('âœ… src.core importable')"
    
    - name: Run core tests
      run: |
        echo "================================"
        echo "Running Core Tests"
        echo "================================"
        pytest tests/test_core.py -v --tb=short
    
    - name: Run SSC computation tests
      run: |
        echo "================================"
        echo "Running SSC Computation Tests"
        echo "================================"
        pytest tests/test_ssc_computation.py -v --tb=short
    
    - name: Run deterministic tests
      run: |
        echo "================================"
        echo "Running Deterministic Tests"
        echo "================================"
        pytest tests/test_deterministic.py -v --tb=short
    
    - name: Run experiment structure tests
      run: |
        echo "================================"
        echo "Running Experiment Tests"
        echo "================================"
        pytest tests/test_experiments.py -v --tb=short
    
    - name: Run full test suite with coverage
      run: |
        echo "================================"
        echo "Running Full Test Suite with Coverage"
        echo "================================"
        pytest tests/ -v --tb=short --cov=src --cov-report=term-missing --cov-report=html:coverage_html --html=test_report.html --self-contained-html
    
    - name: Check coverage threshold
      continue-on-error: true
      run: |
        echo "Checking coverage threshold..."
        coverage report --fail-under=80 || echo "Warning: Coverage below 80%"
    
    - name: Upload coverage reports
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: test-coverage-${{ github.run_number }}
        path: |
          coverage_html/
          test_report.html
        retention-days: 30
    
    - name: Generate test summary
      if: always()
      run: |
        python3 << 'PYTHON_EOF'
        import subprocess
        from pathlib import Path
        
        print("=" * 70)
        print("Test Suite Summary")
        print("=" * 70)
        
        test_files = list(Path("tests").glob("test_*.py"))
        print(f"\nTest files: {len(test_files)}")
        for f in sorted(test_files):
            print(f"  - {f.name}")
        
        result = subprocess.run(
            ["pytest", "tests/", "--collect-only", "-q"],
            capture_output=True,
            text=True
        )
        
        if result.returncode == 0 or result.returncode == 5:
            lines = result.stdout.strip().split('\n')
            if lines:
                last_line = lines[-1]
                print(f"\n{last_line}")
        
        print("\n" + "=" * 70)
        PYTHON_EOF
    
    - name: Summary report
      if: always()
      run: |
        cat >> $GITHUB_STEP_SUMMARY << 'EOF'
        # Intelligence Relativity - Test Suite Results
        
        **Repository**: `intelligence-relativity`
        
        **Python Version**: ${{ matrix.python-version }}
        
        ---
        
        ## Test Categories
        
        | Category | Description | Status |
        |----------|-------------|--------|
        | **Core Tests** | Core measurement toolkit | âœ… Executed |
        | **SSC Computation** | SSC measurement validation | âœ… Executed |
        | **Deterministic** | Reproducibility guarantees | âœ… Executed |
        | **Experiments** | Experiment structure | âœ… Executed |
        
        ---
        
        ## Coverage Report
        
        - **Coverage Report**: Available in artifacts
        - **HTML Report**: `test_report.html`
        - **Threshold**: 80% (recommended)
        
        ---
        
        ## Test Categories Details
        
        ### Core Tests (`test_core.py`)
        - Deterministic mode setup
        - Environment verification
        - Data generation utilities
        - Statistical tools
        - Manifest generation
        
        ### SSC Computation Tests (`test_ssc_computation.py`)
        - Perfect correlation detection
        - Zero correlation (O-1) validation
        - Input validation
        - Cross-implementation consistency
        - Numerical stability
        
        ### Deterministic Tests (`test_deterministic.py`)
        - Environment variable setup
        - Perfect reproducibility
        - Hash stability
        - Bootstrap reproducibility
        - Cross-implementation consistency
        
        ### Experiment Tests (`test_experiments.py`)
        - Module import validation
        - Required function presence
        - Parameter consistency
        - Output structure validation
        
        ---
        
        ## Download
        
        - ðŸ“¦ **Coverage Report**: `test-coverage-${{ github.run_number }}.zip`
        
        ---
        
        **All tests validate the core measurement instruments for Intelligence Relativity**
        EOF

  lint:
    name: Code Quality Check
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
    
    - name: Install linting tools
      run: |
        pip install flake8 black isort
    
    - name: Check code formatting with black
      continue-on-error: true
      run: |
        echo "Checking code formatting..."
        black --check src/ tests/ || echo "âš ï¸  Code formatting issues found"
    
    - name: Check import sorting with isort
      continue-on-error: true
      run: |
        echo "Checking import sorting..."
        isort --check-only src/ tests/ || echo "âš ï¸  Import sorting issues found"
    
    - name: Lint with flake8
      continue-on-error: true
      run: |
        echo "Running flake8..."
        flake8 src/ tests/ --max-line-length=100 --ignore=E203,W503 || echo "âš ï¸  Linting issues found"
    
    - name: Summary
      run: |
        cat >> $GITHUB_STEP_SUMMARY << 'EOF'
        # Code Quality Check
        
        ## Checks Performed
        
        - âœ… **Black**: Code formatting
        - âœ… **isort**: Import sorting
        - âœ… **flake8**: Code linting
        
        ---
        
        **Note**: These checks are informational and do not block the workflow
        EOF

  integration:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: test
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python 3.11
      uses: actions/setup-python@v5
      with:
        python-version: '3.11'
    
    - name: Install dependencies
      run: |
        pip install -r requirements.txt
        pip install -e .
    
    - name: Run mini experiment
      run: |
        python3 << 'PYTHON_EOF'
        import sys
        import numpy as np
        from pathlib import Path
        
        from src.core import (
            set_deterministic_mode,
            generate_embeddings,
            generate_spatial_coords,
            compute_ssc_from_data,
            compute_summary_stats
        )
        
        print("=" * 70)
        print("Integration Test: Mini EXP-00")
        print("=" * 70)
        
        set_deterministic_mode()
        n_items, dim, n_trials, seed = 20, 100, 10, 42
        
        ssc_values = []
        for i in range(n_trials):
            emb = generate_embeddings(n_items, dim, seed + i)
            coords = generate_spatial_coords(n_items, "random", seed + i)
            ssc = compute_ssc_from_data(emb, coords)
            ssc_values.append(ssc)
        
        stats = compute_summary_stats(np.array(ssc_values))
        
        print(f"\nResults (N={n_trials}):")
        print(f"  Mean: {stats['mean']:.4f}")
        print(f"  Std:  {stats['std']:.4f}")
        print(f"  Range: [{stats['min']:.4f}, {stats['max']:.4f}]")
        
        assert abs(stats['mean']) < 0.2, f"Mean SSC outside expected range: {stats['mean']}"
        
        print("\nâœ… Integration test passed")
        print("=" * 70)
        PYTHON_EOF
    
    - name: Verify reproducibility
      run: |
        python3 << 'PYTHON_EOF'
        import sys
        import numpy as np
        from pathlib import Path
        
        from src.core import (
            set_deterministic_mode,
            generate_embeddings,
            compute_ssc_from_data,
            generate_spatial_coords
        )
        
        print("=" * 70)
        print("Reproducibility Verification")
        print("=" * 70)
        
        set_deterministic_mode()
        seed = 42
        
        emb1 = generate_embeddings(20, 100, seed)
        coords1 = generate_spatial_coords(20, "circle", seed)
        ssc1 = compute_ssc_from_data(emb1, coords1)
        
        emb2 = generate_embeddings(20, 100, seed)
        coords2 = generate_spatial_coords(20, "circle", seed)
        ssc2 = compute_ssc_from_data(emb2, coords2)
        
        np.testing.assert_array_equal(emb1, emb2)
        np.testing.assert_array_equal(coords1, coords2)
        assert ssc1 == ssc2
        
        print(f"\nSSC (Run 1): {ssc1:.10f}")
        print(f"SSC (Run 2): {ssc2:.10f}")
        print(f"Difference:  {abs(ssc1 - ssc2):.2e}")
        
        print("\nâœ… Perfect reproducibility confirmed")
        print("=" * 70)
        PYTHON_EOF
    
    - name: Integration summary
      run: |
        cat >> $GITHUB_STEP_SUMMARY << 'EOF'
        # Integration Tests
        
        ## Tests Performed
        
        - âœ… **Mini Experiment**: EXP-00 with N=10
        - âœ… **Reproducibility**: Bit-for-bit verification
        
        ---
        
        ## Results
        
        - **O-1 Validation**: SSC â‰ˆ 0 confirmed
        - **Determinism**: Perfect reproducibility
        - **Integration**: Full pipeline functional
        
        ---
        
        **All integration tests passed successfully**
        EOF
